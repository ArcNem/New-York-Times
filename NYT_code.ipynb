{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Headline</th>\n",
       "      <th>NewsDesk</th>\n",
       "      <th>Popular</th>\n",
       "      <th>PubDate</th>\n",
       "      <th>SectionName</th>\n",
       "      <th>Snippet</th>\n",
       "      <th>SubsectionName</th>\n",
       "      <th>UniqueID</th>\n",
       "      <th>WordCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A puzzle from Ethan Cooper that reminds me tha...</td>\n",
       "      <td>More School Daze</td>\n",
       "      <td>Business</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2014-09-01 22:00:09</td>\n",
       "      <td>Crosswords/Games</td>\n",
       "      <td>A puzzle from Ethan Cooper that reminds me tha...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Strange Library will arrive just three and...</td>\n",
       "      <td>New 96-Page Murakami Work Coming in December</td>\n",
       "      <td>Culture</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014-09-01 21:14:07</td>\n",
       "      <td>Arts</td>\n",
       "      <td>The Strange Library will arrive just three and...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Public pension funds have major stakes in Amer...</td>\n",
       "      <td>Public Pension Funds Stay Mum on Corporate Expats</td>\n",
       "      <td>Business</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014-09-01 21:05:36</td>\n",
       "      <td>Business Day</td>\n",
       "      <td>Public pension funds have major stakes in Amer...</td>\n",
       "      <td>Dealbook</td>\n",
       "      <td>3</td>\n",
       "      <td>1211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>As they struggle to find new business to bolst...</td>\n",
       "      <td>Boot Camp for Bankers</td>\n",
       "      <td>Business</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2014-09-01 20:43:34</td>\n",
       "      <td>Business Day</td>\n",
       "      <td>As they struggle to find new business to bolst...</td>\n",
       "      <td>Dealbook</td>\n",
       "      <td>4</td>\n",
       "      <td>1405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Middle-aged and older patients are unlikely to...</td>\n",
       "      <td>Of Little Help to Older Knees</td>\n",
       "      <td>Science</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2014-09-01 18:58:51</td>\n",
       "      <td>Health</td>\n",
       "      <td>Middle-aged and older patients are unlikely to...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Abstract  \\\n",
       "0  A puzzle from Ethan Cooper that reminds me tha...   \n",
       "1  The Strange Library will arrive just three and...   \n",
       "2  Public pension funds have major stakes in Amer...   \n",
       "3  As they struggle to find new business to bolst...   \n",
       "4  Middle-aged and older patients are unlikely to...   \n",
       "\n",
       "                                            Headline  NewsDesk  Popular  \\\n",
       "0                                   More School Daze  Business      1.0   \n",
       "1       New 96-Page Murakami Work Coming in December   Culture      0.0   \n",
       "2  Public Pension Funds Stay Mum on Corporate Expats  Business      0.0   \n",
       "3                              Boot Camp for Bankers  Business      1.0   \n",
       "4                      Of Little Help to Older Knees   Science      1.0   \n",
       "\n",
       "               PubDate       SectionName  \\\n",
       "0  2014-09-01 22:00:09  Crosswords/Games   \n",
       "1  2014-09-01 21:14:07              Arts   \n",
       "2  2014-09-01 21:05:36      Business Day   \n",
       "3  2014-09-01 20:43:34      Business Day   \n",
       "4  2014-09-01 18:58:51            Health   \n",
       "\n",
       "                                             Snippet SubsectionName  UniqueID  \\\n",
       "0  A puzzle from Ethan Cooper that reminds me tha...            NaN         1   \n",
       "1  The Strange Library will arrive just three and...            NaN         2   \n",
       "2  Public pension funds have major stakes in Amer...       Dealbook         3   \n",
       "3  As they struggle to find new business to bolst...       Dealbook         4   \n",
       "4  Middle-aged and older patients are unlikely to...            NaN         5   \n",
       "\n",
       "   WordCount  \n",
       "0        508  \n",
       "1        285  \n",
       "2       1211  \n",
       "3       1405  \n",
       "4        181  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "nyt_train = pd.read_csv('NYTimesBlogTrain.csv')\n",
    "nyt_test = pd.read_csv('NYTimesBlogTest.csv')\n",
    "\n",
    "nyt_full = pd.concat((nyt_train,nyt_test))\n",
    "nyt_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Adding frequency of headline as a feature\n",
    "nyt_full[\"HeadlineFreq\"] = nyt_full.Headline.map(nyt_full.Headline.value_counts())\n",
    "\n",
    "#Adding number of words in the headline as a feature\n",
    "nyt_full['HeadlineWords'] = nyt_full.Headline.apply(lambda x: len(str(x).split(' ')))\n",
    "\n",
    "#Adding number of words in the abstract as a feature\n",
    "nyt_full['AbstractWords'] = nyt_full.Abstract.apply(lambda x: len(str(x).split(' ')))\n",
    "\n",
    "#Adding number of question/exclamation mark as a feature\n",
    "nyt_full['new2']=nyt_full[['Headline']].applymap(lambda x: str.count(x, '?'))\n",
    "nyt_full['new3']=nyt_full[['Headline']].applymap(lambda x: str.count(x, '!'))\n",
    "nyt_full['HeadlineProps']= nyt_full.new2 + nyt_full.new3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NewsDesk</th>\n",
       "      <th>SectionName</th>\n",
       "      <th>SubsectionName</th>\n",
       "      <th>WordCount</th>\n",
       "      <th>HeadlineWords</th>\n",
       "      <th>AbstractWords</th>\n",
       "      <th>HeadlineFreq</th>\n",
       "      <th>HeadlineProps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Business</td>\n",
       "      <td>Crosswords/Games</td>\n",
       "      <td>NaN</td>\n",
       "      <td>508</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Culture</td>\n",
       "      <td>Arts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>285</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Business</td>\n",
       "      <td>Business Day</td>\n",
       "      <td>Dealbook</td>\n",
       "      <td>1211</td>\n",
       "      <td>8</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Business</td>\n",
       "      <td>Business Day</td>\n",
       "      <td>Dealbook</td>\n",
       "      <td>1405</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Science</td>\n",
       "      <td>Health</td>\n",
       "      <td>NaN</td>\n",
       "      <td>181</td>\n",
       "      <td>6</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NewsDesk       SectionName SubsectionName  WordCount  HeadlineWords  \\\n",
       "0  Business  Crosswords/Games            NaN        508              3   \n",
       "1   Culture              Arts            NaN        285              7   \n",
       "2  Business      Business Day       Dealbook       1211              8   \n",
       "3  Business      Business Day       Dealbook       1405              4   \n",
       "4   Science            Health            NaN        181              6   \n",
       "\n",
       "   AbstractWords  HeadlineFreq  HeadlineProps  \n",
       "0             13             1              0  \n",
       "1             24             1              0  \n",
       "2             31             1              0  \n",
       "3             23             1              0  \n",
       "4             33             1              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyt2 = nyt_full[['NewsDesk','SectionName','SubsectionName','WordCount','HeadlineWords','AbstractWords','HeadlineFreq', 'HeadlineProps']]\n",
    "nyt2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arcane_rt5\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NewsDesk</th>\n",
       "      <th>SectionName</th>\n",
       "      <th>SubsectionName</th>\n",
       "      <th>WordCount</th>\n",
       "      <th>HeadlineWords</th>\n",
       "      <th>AbstractWords</th>\n",
       "      <th>HeadlineFreq</th>\n",
       "      <th>HeadlineProps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>508</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>285</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1211</td>\n",
       "      <td>8</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1405</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "      <td>6</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NewsDesk  SectionName  SubsectionName  WordCount  HeadlineWords  \\\n",
       "0         9            2               0        508              3   \n",
       "1        12           14               0        285              7   \n",
       "2         9            3               2       1211              8   \n",
       "3         9            3               2       1405              4   \n",
       "4        10            8               0        181              6   \n",
       "\n",
       "   AbstractWords  HeadlineFreq  HeadlineProps  \n",
       "0             13             1              0  \n",
       "1             24             1              0  \n",
       "2             31             1              0  \n",
       "3             23             1              0  \n",
       "4             33             1              0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Function to map non-numerical categorical data to its numerical counterparts\n",
    "\n",
    "def handle_non_numerical_data(df):\n",
    "    columns = df.columns.values\n",
    "    \n",
    "    for column in columns:\n",
    "        text_digit_vals={}\n",
    "        def convert_to_int(val):\n",
    "            return text_digit_vals[val]\n",
    "        \n",
    "        if df[column].dtype != np.int64 and df[column].dtype != np.float64:\n",
    "            column_contents = df[column].values.tolist()\n",
    "            unique_elements = set(column_contents)\n",
    "            x=0\n",
    "            for unique in unique_elements:\n",
    "                if unique not in text_digit_vals:\n",
    "                    text_digit_vals[unique] = x\n",
    "                    x+=1\n",
    "                    \n",
    "            df[column] = list(map(convert_to_int, df[column]))\n",
    "    return df\n",
    "\n",
    "nyt3 = handle_non_numerical_data(nyt2)\n",
    "nyt3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000',\n",
       " '006',\n",
       " '010',\n",
       " '02',\n",
       " '03',\n",
       " '08',\n",
       " '09',\n",
       " '10',\n",
       " '100',\n",
       " '100000003149882',\n",
       " '100000003149892',\n",
       " '100th',\n",
       " '101',\n",
       " '105',\n",
       " '106',\n",
       " '107',\n",
       " '108',\n",
       " '10th',\n",
       " '10x',\n",
       " '11',\n",
       " '110',\n",
       " '111',\n",
       " '113th',\n",
       " '114',\n",
       " '114th',\n",
       " '115',\n",
       " '1159',\n",
       " '117',\n",
       " '11th',\n",
       " '12',\n",
       " '120',\n",
       " '122',\n",
       " '123',\n",
       " '125',\n",
       " '127',\n",
       " '129',\n",
       " '12th',\n",
       " '13',\n",
       " '130',\n",
       " '13th',\n",
       " '14',\n",
       " '140',\n",
       " '140th',\n",
       " '142',\n",
       " '147',\n",
       " '149',\n",
       " '14th',\n",
       " '15',\n",
       " '150',\n",
       " '150th',\n",
       " '159',\n",
       " '15th',\n",
       " '16',\n",
       " '160',\n",
       " '161',\n",
       " '164',\n",
       " '165th',\n",
       " '169',\n",
       " '16th',\n",
       " '17',\n",
       " '171',\n",
       " '174',\n",
       " '175',\n",
       " '17th',\n",
       " '18',\n",
       " '180',\n",
       " '1800',\n",
       " '1803',\n",
       " '1812',\n",
       " '1821',\n",
       " '1822',\n",
       " '1850',\n",
       " '1851',\n",
       " '1859',\n",
       " '186',\n",
       " '1860s',\n",
       " '1862',\n",
       " '1863',\n",
       " '1864',\n",
       " '187',\n",
       " '188',\n",
       " '1888',\n",
       " '1889',\n",
       " '1892',\n",
       " '18th',\n",
       " '19',\n",
       " '1909',\n",
       " '191',\n",
       " '1912',\n",
       " '1914',\n",
       " '1916',\n",
       " '1918',\n",
       " '1924',\n",
       " '1936',\n",
       " '1938',\n",
       " '1939',\n",
       " '194',\n",
       " '1940',\n",
       " '1943',\n",
       " '1944',\n",
       " '1948',\n",
       " '1950s',\n",
       " '1951',\n",
       " '1952',\n",
       " '1953',\n",
       " '1955',\n",
       " '1956',\n",
       " '1958',\n",
       " '1959',\n",
       " '196',\n",
       " '1960',\n",
       " '1960s',\n",
       " '1961',\n",
       " '1962',\n",
       " '1963',\n",
       " '1964',\n",
       " '1965',\n",
       " '1966',\n",
       " '1967',\n",
       " '1968',\n",
       " '1969',\n",
       " '1969s',\n",
       " '1970s',\n",
       " '1971',\n",
       " '1972',\n",
       " '1973',\n",
       " '1974',\n",
       " '1975',\n",
       " '1976',\n",
       " '1977',\n",
       " '1980',\n",
       " '1980s',\n",
       " '1981',\n",
       " '1984',\n",
       " '1985',\n",
       " '1986',\n",
       " '1987',\n",
       " '1988',\n",
       " '1989',\n",
       " '1990s',\n",
       " '1991',\n",
       " '1992',\n",
       " '1993',\n",
       " '1994',\n",
       " '1995',\n",
       " '1996',\n",
       " '1997',\n",
       " '1998',\n",
       " '1999',\n",
       " '19th',\n",
       " '1st',\n",
       " '20',\n",
       " '200',\n",
       " '2000',\n",
       " '2001',\n",
       " '2002',\n",
       " '2003',\n",
       " '2004',\n",
       " '2005',\n",
       " '2006',\n",
       " '2007',\n",
       " '2008',\n",
       " '2009',\n",
       " '201',\n",
       " '2010',\n",
       " '2011',\n",
       " '2012',\n",
       " '2013',\n",
       " '2014',\n",
       " '2015',\n",
       " '2016',\n",
       " '2017',\n",
       " '2018',\n",
       " '204',\n",
       " '20th',\n",
       " '21',\n",
       " '2100',\n",
       " '2114',\n",
       " '213',\n",
       " '214',\n",
       " '21st',\n",
       " '22',\n",
       " '225',\n",
       " '228',\n",
       " '23',\n",
       " '230',\n",
       " '232',\n",
       " '239',\n",
       " '24',\n",
       " '240',\n",
       " '242',\n",
       " '245',\n",
       " '25',\n",
       " '250',\n",
       " '252',\n",
       " '25th',\n",
       " '26',\n",
       " '268',\n",
       " '26th',\n",
       " '27',\n",
       " '278',\n",
       " '28',\n",
       " '280',\n",
       " '28th',\n",
       " '29',\n",
       " '294',\n",
       " '2nd',\n",
       " '30',\n",
       " '300',\n",
       " '3000',\n",
       " '30th',\n",
       " '31',\n",
       " '315',\n",
       " '319',\n",
       " '32',\n",
       " '323',\n",
       " '325',\n",
       " '32nd',\n",
       " '33',\n",
       " '330',\n",
       " '331',\n",
       " '34',\n",
       " '343',\n",
       " '34th',\n",
       " '35',\n",
       " '350',\n",
       " '350th',\n",
       " '355',\n",
       " '35th',\n",
       " '36',\n",
       " '363',\n",
       " '37',\n",
       " '375',\n",
       " '37th',\n",
       " '38',\n",
       " '380',\n",
       " '39',\n",
       " '397',\n",
       " '3d',\n",
       " '3rd',\n",
       " '3rdeyegirl',\n",
       " '40',\n",
       " '400',\n",
       " '402',\n",
       " '40th',\n",
       " '41',\n",
       " '412',\n",
       " '42',\n",
       " '425',\n",
       " '43',\n",
       " '431',\n",
       " '433',\n",
       " '44',\n",
       " '45',\n",
       " '450',\n",
       " '46',\n",
       " '460',\n",
       " '466',\n",
       " '47',\n",
       " '47th',\n",
       " '48',\n",
       " '480',\n",
       " '488',\n",
       " '493',\n",
       " '50',\n",
       " '500',\n",
       " '500th',\n",
       " '50s',\n",
       " '50th',\n",
       " '51',\n",
       " '52',\n",
       " '527',\n",
       " '53',\n",
       " '530',\n",
       " '531',\n",
       " '535',\n",
       " '54',\n",
       " '542',\n",
       " '55',\n",
       " '550',\n",
       " '55th',\n",
       " '56',\n",
       " '568',\n",
       " '57',\n",
       " '58',\n",
       " '580',\n",
       " '59',\n",
       " '590',\n",
       " '59e59',\n",
       " '5s',\n",
       " '60',\n",
       " '600',\n",
       " '605',\n",
       " '60s',\n",
       " '60th',\n",
       " '61',\n",
       " '6120',\n",
       " '62',\n",
       " '625',\n",
       " '627',\n",
       " '63',\n",
       " '635',\n",
       " '64',\n",
       " '65',\n",
       " '650',\n",
       " '66',\n",
       " '660',\n",
       " '68',\n",
       " '680',\n",
       " '685',\n",
       " '69',\n",
       " '69th',\n",
       " '6s',\n",
       " '6th',\n",
       " '70',\n",
       " '700',\n",
       " '70s',\n",
       " '70th',\n",
       " '71',\n",
       " '72',\n",
       " '73',\n",
       " '73rd',\n",
       " '74',\n",
       " '740',\n",
       " '749',\n",
       " '75',\n",
       " '750',\n",
       " '75th',\n",
       " '76',\n",
       " '769',\n",
       " '76ers',\n",
       " '77',\n",
       " '770',\n",
       " '78',\n",
       " '79',\n",
       " '790',\n",
       " '79th',\n",
       " '80',\n",
       " '800',\n",
       " '802',\n",
       " '80s',\n",
       " '80th',\n",
       " '81',\n",
       " '810',\n",
       " '82',\n",
       " '83',\n",
       " '840',\n",
       " '85',\n",
       " '860',\n",
       " '870',\n",
       " '89',\n",
       " '8s',\n",
       " '90',\n",
       " '900',\n",
       " '90s',\n",
       " '91',\n",
       " '910',\n",
       " '911',\n",
       " '92',\n",
       " '924',\n",
       " '92nd',\n",
       " '93',\n",
       " '94',\n",
       " '95',\n",
       " '950',\n",
       " '96',\n",
       " '960',\n",
       " '97',\n",
       " '98',\n",
       " '99',\n",
       " '_r',\n",
       " 'aaron',\n",
       " 'aasar',\n",
       " 'abandon',\n",
       " 'abandoned',\n",
       " 'abbas',\n",
       " 'abbey',\n",
       " 'abbott',\n",
       " 'abbvie',\n",
       " 'abc',\n",
       " 'abcs',\n",
       " 'abderrahmane',\n",
       " 'abe',\n",
       " 'abiah',\n",
       " 'abide',\n",
       " 'abiding',\n",
       " 'abigail',\n",
       " 'ability',\n",
       " 'abinbev',\n",
       " 'able',\n",
       " 'abn',\n",
       " 'abnormal',\n",
       " 'abolish',\n",
       " 'abolished',\n",
       " 'abolition',\n",
       " 'abortion',\n",
       " 'abortions',\n",
       " 'abounaddara',\n",
       " 'abound',\n",
       " 'about',\n",
       " 'above',\n",
       " 'abraham',\n",
       " 'abrahams',\n",
       " 'abramovic',\n",
       " 'abramovics',\n",
       " 'abrams',\n",
       " 'abroad',\n",
       " 'abrupt',\n",
       " 'abruptly',\n",
       " 'absence',\n",
       " 'absent',\n",
       " 'absentee',\n",
       " 'absolutely',\n",
       " 'absorb',\n",
       " 'abstract',\n",
       " 'absurd',\n",
       " 'abundance',\n",
       " 'abuse',\n",
       " 'abused',\n",
       " 'abuser',\n",
       " 'abusers',\n",
       " 'abuses',\n",
       " 'abusive',\n",
       " 'abuzz',\n",
       " 'academia',\n",
       " 'academic',\n",
       " 'academics',\n",
       " 'academy',\n",
       " 'academys',\n",
       " 'acadian',\n",
       " 'acapulcos',\n",
       " 'acar',\n",
       " 'accelerating',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'acceptance',\n",
       " 'accepted',\n",
       " 'accepting',\n",
       " 'accepts',\n",
       " 'access',\n",
       " 'accessed',\n",
       " 'accessing',\n",
       " 'accessories',\n",
       " 'accessory',\n",
       " 'accident',\n",
       " 'accidentally',\n",
       " 'accidents',\n",
       " 'acclaim',\n",
       " 'acclaimed',\n",
       " 'accolade',\n",
       " 'accommodate',\n",
       " 'accommodation',\n",
       " 'accommodations',\n",
       " 'accompanied',\n",
       " 'accompaniment',\n",
       " 'accompanying',\n",
       " 'accomplishes',\n",
       " 'accomplishments',\n",
       " 'accord',\n",
       " 'according',\n",
       " 'accosting',\n",
       " 'account',\n",
       " 'accountability',\n",
       " 'accountable',\n",
       " 'accountant',\n",
       " 'accounting',\n",
       " 'accounts',\n",
       " 'accouterments',\n",
       " 'accreditation',\n",
       " 'accredited',\n",
       " 'accumulated',\n",
       " 'accumulation',\n",
       " 'accuracy',\n",
       " 'accurate',\n",
       " 'accusations',\n",
       " 'accuse',\n",
       " 'accused',\n",
       " 'accuser',\n",
       " 'accuses',\n",
       " 'accustomed',\n",
       " 'ace',\n",
       " 'acetate',\n",
       " 'achatz',\n",
       " 'achieve',\n",
       " 'achieved',\n",
       " 'achievement',\n",
       " 'achieving',\n",
       " 'achilles',\n",
       " 'acid',\n",
       " 'ackman',\n",
       " 'ackmans',\n",
       " 'acknowledge',\n",
       " 'acknowledged',\n",
       " 'acknowledges',\n",
       " 'acknowledging',\n",
       " 'acknowledgment',\n",
       " 'acompli',\n",
       " 'acorn',\n",
       " 'acosta',\n",
       " 'acoustics',\n",
       " 'acquaintance',\n",
       " 'acquire',\n",
       " 'acquired',\n",
       " 'acquirers',\n",
       " 'acquires',\n",
       " 'acquiring',\n",
       " 'acquisition',\n",
       " 'acquisitions',\n",
       " 'acquitted',\n",
       " 'acre',\n",
       " 'acres',\n",
       " 'acrimonious',\n",
       " 'acrobatics',\n",
       " 'across',\n",
       " 'acrostic',\n",
       " 'act',\n",
       " 'actavis',\n",
       " 'acted',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'actions',\n",
       " 'activated',\n",
       " 'activating',\n",
       " 'active',\n",
       " 'actively',\n",
       " 'activewear',\n",
       " 'activision',\n",
       " 'activist',\n",
       " 'activists',\n",
       " 'activities',\n",
       " 'activity',\n",
       " 'actor',\n",
       " 'actors',\n",
       " 'actress',\n",
       " 'actresss',\n",
       " 'acts',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'ad',\n",
       " 'adair',\n",
       " 'adam',\n",
       " 'adams',\n",
       " 'adapt',\n",
       " 'adaptation',\n",
       " 'adaptations',\n",
       " 'adapted',\n",
       " 'adaptimmune',\n",
       " 'adapting',\n",
       " 'add',\n",
       " 'addams',\n",
       " 'addario',\n",
       " 'added',\n",
       " 'addict',\n",
       " 'addiction',\n",
       " 'adding',\n",
       " 'addison',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'address',\n",
       " 'addressable',\n",
       " 'addressed',\n",
       " 'addresses',\n",
       " 'addressing',\n",
       " 'adds',\n",
       " 'adelaide',\n",
       " 'adele',\n",
       " 'adeles',\n",
       " 'adeline',\n",
       " 'adelson',\n",
       " 'adept',\n",
       " 'adequate',\n",
       " 'adha',\n",
       " 'adherents',\n",
       " 'adhering',\n",
       " 'adidas',\n",
       " 'adieu',\n",
       " 'adjective',\n",
       " 'adjust',\n",
       " 'adjusted',\n",
       " 'adjustments',\n",
       " 'adm',\n",
       " 'administered',\n",
       " 'administration',\n",
       " 'administrations',\n",
       " 'administrative',\n",
       " 'administrator',\n",
       " 'administrators',\n",
       " 'admiral',\n",
       " 'admires',\n",
       " 'admission',\n",
       " 'admit',\n",
       " 'admitted',\n",
       " 'admitting',\n",
       " 'admonishment',\n",
       " 'admonishments',\n",
       " 'adner',\n",
       " 'adolescence',\n",
       " 'adolescents',\n",
       " 'adolf',\n",
       " 'adolphe',\n",
       " 'adopted',\n",
       " 'adoptees',\n",
       " 'adopting',\n",
       " 'adoption',\n",
       " 'adoptions',\n",
       " 'adopts',\n",
       " 'adorable',\n",
       " 'adorably',\n",
       " 'adore',\n",
       " 'adorn',\n",
       " 'adorned',\n",
       " 'adrangi',\n",
       " 'adressed',\n",
       " 'adrian',\n",
       " 'adriana',\n",
       " 'ads',\n",
       " 'adult',\n",
       " 'adulthood',\n",
       " 'adults',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advances',\n",
       " 'advancing',\n",
       " 'advanstar',\n",
       " 'advantage',\n",
       " 'advantages',\n",
       " 'advent',\n",
       " 'adventure',\n",
       " 'adventures',\n",
       " 'adventurous',\n",
       " 'adversaries',\n",
       " 'advertised',\n",
       " 'advertisement',\n",
       " 'advertisements',\n",
       " 'advertisers',\n",
       " 'advertising',\n",
       " 'advice',\n",
       " 'advise',\n",
       " 'advised',\n",
       " 'adviser',\n",
       " 'advisers',\n",
       " 'advising',\n",
       " 'advisories',\n",
       " 'advisors',\n",
       " 'advisory',\n",
       " 'advocacy',\n",
       " 'advocate',\n",
       " 'advocated',\n",
       " 'advocates',\n",
       " 'advocating',\n",
       " 'adwords',\n",
       " 'adyen',\n",
       " 'aer',\n",
       " 'aereo',\n",
       " 'aerial',\n",
       " 'aerobic',\n",
       " 'aerospace',\n",
       " 'aesop',\n",
       " 'aesthetic',\n",
       " 'affair',\n",
       " 'affairs',\n",
       " 'affect',\n",
       " 'affected',\n",
       " 'affecting',\n",
       " 'affection',\n",
       " 'affectionate',\n",
       " 'affects',\n",
       " 'affiliate',\n",
       " 'affiliated',\n",
       " 'affinity',\n",
       " 'affirmative',\n",
       " 'afflict',\n",
       " 'afflicted',\n",
       " 'afflicts',\n",
       " 'affluent',\n",
       " 'afford',\n",
       " 'affordable',\n",
       " 'afghan',\n",
       " 'afghanistan',\n",
       " 'afghanistans',\n",
       " 'afghans',\n",
       " 'afield',\n",
       " 'afloat',\n",
       " 'afoot',\n",
       " 'afoul',\n",
       " 'afresheet',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'africans',\n",
       " 'africas',\n",
       " 'after',\n",
       " 'aftereffects',\n",
       " 'aftermath',\n",
       " 'afternoon',\n",
       " 'afternoons',\n",
       " 'aftertastes',\n",
       " 'afterward',\n",
       " 'again',\n",
       " 'against',\n",
       " 'agards',\n",
       " 'agave',\n",
       " 'age',\n",
       " 'aged',\n",
       " 'agencies',\n",
       " 'agency',\n",
       " 'agencys',\n",
       " 'agenda',\n",
       " 'agent',\n",
       " 'agents',\n",
       " 'ages',\n",
       " 'aggregators',\n",
       " 'aggression',\n",
       " 'aggressive',\n",
       " 'aggressively',\n",
       " 'aging',\n",
       " 'agnew',\n",
       " 'ago',\n",
       " 'agree',\n",
       " 'agreed',\n",
       " 'agreement',\n",
       " 'agreements',\n",
       " 'agrees',\n",
       " 'agriculture',\n",
       " 'ahead',\n",
       " 'ahmed',\n",
       " 'ai',\n",
       " 'aid',\n",
       " 'aida',\n",
       " 'aide',\n",
       " 'aidens',\n",
       " 'aides',\n",
       " 'aiding',\n",
       " 'aids',\n",
       " 'aiken',\n",
       " 'ailey',\n",
       " 'ailments',\n",
       " 'aim',\n",
       " 'aimed',\n",
       " 'aiming',\n",
       " 'aims',\n",
       " 'aint',\n",
       " 'air',\n",
       " 'airbags',\n",
       " 'airbnb',\n",
       " 'airborne',\n",
       " 'aircraft',\n",
       " 'aires',\n",
       " 'airfield',\n",
       " 'airing',\n",
       " 'airline',\n",
       " 'airlines',\n",
       " 'airmen',\n",
       " 'airplanes',\n",
       " 'airport',\n",
       " 'airports',\n",
       " 'airs',\n",
       " 'airshow',\n",
       " 'airstrikes',\n",
       " 'airtime',\n",
       " 'airwaves',\n",
       " 'airways',\n",
       " 'aix',\n",
       " 'akai',\n",
       " 'akhtar',\n",
       " 'akin',\n",
       " 'akselrad',\n",
       " 'akshaya',\n",
       " 'al',\n",
       " 'ala',\n",
       " 'alabama',\n",
       " 'aladdin',\n",
       " 'alan',\n",
       " 'alarm',\n",
       " 'alarmed',\n",
       " 'alaska',\n",
       " 'alayne',\n",
       " 'alba',\n",
       " 'albanias',\n",
       " 'albans',\n",
       " 'albany',\n",
       " 'albees',\n",
       " 'alben',\n",
       " 'albert',\n",
       " 'alberta',\n",
       " 'albertsons',\n",
       " 'albright',\n",
       " 'album',\n",
       " 'albums',\n",
       " 'alcina',\n",
       " 'alcoholics',\n",
       " 'alda',\n",
       " 'aldeans',\n",
       " 'alderman',\n",
       " 'aldrichs',\n",
       " 'alec',\n",
       " 'aleppo',\n",
       " 'alert',\n",
       " 'alerts',\n",
       " 'alesch',\n",
       " 'alessandro',\n",
       " 'alex',\n",
       " 'alexander',\n",
       " 'alexandra',\n",
       " 'alexei',\n",
       " 'alexis',\n",
       " 'alfonso',\n",
       " 'alfred',\n",
       " 'alfredo',\n",
       " 'algeria',\n",
       " 'algerian',\n",
       " 'ali',\n",
       " 'alias',\n",
       " 'alibaba',\n",
       " 'alibabas',\n",
       " 'alice',\n",
       " 'alicia',\n",
       " 'alienated',\n",
       " 'align',\n",
       " 'alike',\n",
       " 'alimentation',\n",
       " 'alios',\n",
       " 'alisher',\n",
       " 'alison',\n",
       " 'alisons',\n",
       " 'alito',\n",
       " 'alive',\n",
       " 'alixpartners',\n",
       " 'alkylamines',\n",
       " 'all',\n",
       " 'allegations',\n",
       " 'allegedly',\n",
       " 'alleges',\n",
       " 'allegiance',\n",
       " 'allegory',\n",
       " 'allen',\n",
       " 'allergan',\n",
       " 'allergans',\n",
       " 'allergic',\n",
       " 'allergies',\n",
       " 'alleviate',\n",
       " 'alleviation',\n",
       " 'alliance',\n",
       " 'allianz',\n",
       " 'allies',\n",
       " 'allison',\n",
       " 'allman',\n",
       " 'allotted',\n",
       " 'allow',\n",
       " 'allowable',\n",
       " 'allowances',\n",
       " 'allowed',\n",
       " 'allowing',\n",
       " 'allows',\n",
       " 'allure',\n",
       " 'alluring',\n",
       " 'ally',\n",
       " 'almada',\n",
       " 'almond',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'alongside',\n",
       " 'alpha',\n",
       " 'alphabet',\n",
       " 'alpine',\n",
       " 'already',\n",
       " 'alshon',\n",
       " 'also',\n",
       " 'alstoms',\n",
       " 'alt',\n",
       " 'alter',\n",
       " 'altering',\n",
       " 'alternate',\n",
       " 'alternative',\n",
       " 'alternatives',\n",
       " 'although',\n",
       " 'altice',\n",
       " 'altman',\n",
       " 'altogether',\n",
       " 'altuzarra',\n",
       " 'aluminum',\n",
       " 'alumna',\n",
       " 'alumni',\n",
       " 'alumnus',\n",
       " 'alvin',\n",
       " 'always',\n",
       " 'alzheimers',\n",
       " 'am',\n",
       " 'am1',\n",
       " 'ama',\n",
       " 'amagansett',\n",
       " 'amalgam',\n",
       " 'amalie',\n",
       " 'amanda',\n",
       " 'amar',\n",
       " 'amassed',\n",
       " 'amassing',\n",
       " 'amateur',\n",
       " 'amateurs',\n",
       " 'amazing',\n",
       " 'amazingly',\n",
       " 'amazon',\n",
       " 'amazons',\n",
       " 'ambassador',\n",
       " 'amber',\n",
       " 'ambiguous',\n",
       " 'ambika',\n",
       " 'ambitions',\n",
       " 'ambitious',\n",
       " 'ambulance',\n",
       " 'ambush',\n",
       " 'ambushed',\n",
       " 'amendment',\n",
       " 'amendments',\n",
       " 'amenities',\n",
       " 'america',\n",
       " 'american',\n",
       " 'americana',\n",
       " 'americans',\n",
       " 'americas',\n",
       " 'americorps',\n",
       " 'amerli',\n",
       " 'amgen',\n",
       " 'amgens',\n",
       " 'amiably',\n",
       " 'amicable',\n",
       " 'amid',\n",
       " 'amine',\n",
       " 'amir',\n",
       " 'ammunition',\n",
       " 'amnesty',\n",
       " 'among',\n",
       " 'amors',\n",
       " 'amoruso',\n",
       " 'amount',\n",
       " 'amounted',\n",
       " 'amounts',\n",
       " 'amplified',\n",
       " 'amplify',\n",
       " 'amputee',\n",
       " 'amras',\n",
       " 'amrica',\n",
       " 'amro',\n",
       " 'amsterdam',\n",
       " 'amtrak',\n",
       " 'amuse',\n",
       " 'amusement',\n",
       " 'amy',\n",
       " 'amyotrophic',\n",
       " 'an',\n",
       " 'ana',\n",
       " 'anachronistic',\n",
       " 'anagrams',\n",
       " 'anahad',\n",
       " 'analog',\n",
       " 'analysis',\n",
       " 'analysts',\n",
       " 'analytical',\n",
       " 'analytics',\n",
       " 'analyze',\n",
       " 'analyzed',\n",
       " 'analyzing',\n",
       " 'anarchy',\n",
       " 'anastacio',\n",
       " 'anatsuis',\n",
       " 'anbang',\n",
       " 'ancestor',\n",
       " 'ancestors',\n",
       " 'ancestral',\n",
       " 'anchor',\n",
       " 'anchors',\n",
       " 'ancient',\n",
       " 'and',\n",
       " 'anda',\n",
       " 'anderson',\n",
       " 'andersons',\n",
       " 'andersonville',\n",
       " 'andr',\n",
       " 'andrea',\n",
       " 'andreas',\n",
       " 'andreessen',\n",
       " 'andrew',\n",
       " 'andrews',\n",
       " 'andrey',\n",
       " 'andris',\n",
       " 'androgynous',\n",
       " 'android',\n",
       " 'andy',\n",
       " 'anecdotal',\n",
       " 'anemona',\n",
       " 'angel',\n",
       " 'angela',\n",
       " 'angeles',\n",
       " 'angelesbased',\n",
       " 'angeless',\n",
       " 'angelina',\n",
       " 'angelique',\n",
       " 'angelmaier',\n",
       " 'angelo',\n",
       " 'anger',\n",
       " ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer()\n",
    "simple_train = nyt_full['Abstract']\n",
    "simple_trainSM = vect.fit_transform(simple_train.fillna(\" \"))\n",
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8402x18674 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 209669 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix, hstack\n",
    "\n",
    "nyt3SM= csr_matrix(nyt3.values)\n",
    "\n",
    "SM = hstack((nyt3SM, simple_trainSM), format=\"csr\")\n",
    "SM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n",
       "            ...\n",
       "            6522, 6523, 6524, 6525, 6526, 6527, 6528, 6529, 6530, 6531],\n",
       "           dtype='int64', length=6532)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_index = nyt_full[~nyt_full[\"Popular\"].isnull()].index\n",
    "train_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n",
       "            ...\n",
       "            1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869],\n",
       "           dtype='int64', length=1870)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_index = nyt_full[nyt_full[\"Popular\"].isnull()].index\n",
    "test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'n_estimators': [200, 700], 'max_features': ['auto', 'sqrt', 'log2']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "y= nyt_train.Popular\n",
    "\n",
    "param_grid = {'n_estimators': [200, 700],'max_features': ['auto', 'sqrt', 'log2']}\n",
    "\n",
    "gr = GridSearchCV(rfc, param_grid, scoring=\"roc_auc\", n_jobs=-1, cv=4)\n",
    "\n",
    "gr.fit(SM[train_index, :], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92110432007358178"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=700, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.86714286,  0.02857143,  0.05857143, ...,  0.        ,\n",
       "        0.01571429,  0.14571429])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability = gr.best_estimator_.predict_proba(SM[test_index,:])[:,1]\n",
    "probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UniqueID</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6533</td>\n",
       "      <td>0.867143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6534</td>\n",
       "      <td>0.028571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6535</td>\n",
       "      <td>0.058571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6536</td>\n",
       "      <td>0.722857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6537</td>\n",
       "      <td>0.738571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6538</td>\n",
       "      <td>0.754286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6539</td>\n",
       "      <td>0.084286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6540</td>\n",
       "      <td>0.805714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6541</td>\n",
       "      <td>0.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6542</td>\n",
       "      <td>0.059143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6543</td>\n",
       "      <td>0.054286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6544</td>\n",
       "      <td>0.001429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6545</td>\n",
       "      <td>0.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6546</td>\n",
       "      <td>0.901429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6547</td>\n",
       "      <td>0.161429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6548</td>\n",
       "      <td>0.911429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6549</td>\n",
       "      <td>0.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6550</td>\n",
       "      <td>0.108571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6551</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6552</td>\n",
       "      <td>0.111429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6553</td>\n",
       "      <td>0.002857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6554</td>\n",
       "      <td>0.037143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6555</td>\n",
       "      <td>0.001429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6556</td>\n",
       "      <td>0.194286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6557</td>\n",
       "      <td>0.037143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6558</td>\n",
       "      <td>0.062857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6559</td>\n",
       "      <td>0.022857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6560</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6561</td>\n",
       "      <td>0.015714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>6562</td>\n",
       "      <td>0.002857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1840</th>\n",
       "      <td>8373</td>\n",
       "      <td>0.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1841</th>\n",
       "      <td>8374</td>\n",
       "      <td>0.027143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1842</th>\n",
       "      <td>8375</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1843</th>\n",
       "      <td>8376</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1844</th>\n",
       "      <td>8377</td>\n",
       "      <td>0.035714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1845</th>\n",
       "      <td>8378</td>\n",
       "      <td>0.004286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1846</th>\n",
       "      <td>8379</td>\n",
       "      <td>0.001429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1847</th>\n",
       "      <td>8380</td>\n",
       "      <td>0.017143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1848</th>\n",
       "      <td>8381</td>\n",
       "      <td>0.021429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1849</th>\n",
       "      <td>8382</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1850</th>\n",
       "      <td>8383</td>\n",
       "      <td>0.784286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851</th>\n",
       "      <td>8384</td>\n",
       "      <td>0.022857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1852</th>\n",
       "      <td>8385</td>\n",
       "      <td>0.894286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1853</th>\n",
       "      <td>8386</td>\n",
       "      <td>0.681429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1854</th>\n",
       "      <td>8387</td>\n",
       "      <td>0.061429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1855</th>\n",
       "      <td>8388</td>\n",
       "      <td>0.042857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1856</th>\n",
       "      <td>8389</td>\n",
       "      <td>0.021429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1857</th>\n",
       "      <td>8390</td>\n",
       "      <td>0.024286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1858</th>\n",
       "      <td>8391</td>\n",
       "      <td>0.791429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1859</th>\n",
       "      <td>8392</td>\n",
       "      <td>0.834286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>8393</td>\n",
       "      <td>0.014286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861</th>\n",
       "      <td>8394</td>\n",
       "      <td>0.007143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862</th>\n",
       "      <td>8395</td>\n",
       "      <td>0.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1863</th>\n",
       "      <td>8396</td>\n",
       "      <td>0.794286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>8397</td>\n",
       "      <td>0.008571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1865</th>\n",
       "      <td>8398</td>\n",
       "      <td>0.001429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1866</th>\n",
       "      <td>8399</td>\n",
       "      <td>0.012857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867</th>\n",
       "      <td>8400</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1868</th>\n",
       "      <td>8401</td>\n",
       "      <td>0.015714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1869</th>\n",
       "      <td>8402</td>\n",
       "      <td>0.145714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1870 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      UniqueID  Probability\n",
       "0         6533     0.867143\n",
       "1         6534     0.028571\n",
       "2         6535     0.058571\n",
       "3         6536     0.722857\n",
       "4         6537     0.738571\n",
       "5         6538     0.754286\n",
       "6         6539     0.084286\n",
       "7         6540     0.805714\n",
       "8         6541     0.770000\n",
       "9         6542     0.059143\n",
       "10        6543     0.054286\n",
       "11        6544     0.001429\n",
       "12        6545     0.030000\n",
       "13        6546     0.901429\n",
       "14        6547     0.161429\n",
       "15        6548     0.911429\n",
       "16        6549     0.130000\n",
       "17        6550     0.108571\n",
       "18        6551     0.000000\n",
       "19        6552     0.111429\n",
       "20        6553     0.002857\n",
       "21        6554     0.037143\n",
       "22        6555     0.001429\n",
       "23        6556     0.194286\n",
       "24        6557     0.037143\n",
       "25        6558     0.062857\n",
       "26        6559     0.022857\n",
       "27        6560     0.050000\n",
       "28        6561     0.015714\n",
       "29        6562     0.002857\n",
       "...        ...          ...\n",
       "1840      8373     0.080000\n",
       "1841      8374     0.027143\n",
       "1842      8375     0.785714\n",
       "1843      8376     0.010000\n",
       "1844      8377     0.035714\n",
       "1845      8378     0.004286\n",
       "1846      8379     0.001429\n",
       "1847      8380     0.017143\n",
       "1848      8381     0.021429\n",
       "1849      8382     0.000000\n",
       "1850      8383     0.784286\n",
       "1851      8384     0.022857\n",
       "1852      8385     0.894286\n",
       "1853      8386     0.681429\n",
       "1854      8387     0.061429\n",
       "1855      8388     0.042857\n",
       "1856      8389     0.021429\n",
       "1857      8390     0.024286\n",
       "1858      8391     0.791429\n",
       "1859      8392     0.834286\n",
       "1860      8393     0.014286\n",
       "1861      8394     0.007143\n",
       "1862      8395     0.060000\n",
       "1863      8396     0.794286\n",
       "1864      8397     0.008571\n",
       "1865      8398     0.001429\n",
       "1866      8399     0.012857\n",
       "1867      8400     0.000000\n",
       "1868      8401     0.015714\n",
       "1869      8402     0.145714\n",
       "\n",
       "[1870 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = nyt_test[[\"UniqueID\"]].loc[test_index]\n",
    "results[\"Probability\"] = probability\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results.to_csv(\"results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
